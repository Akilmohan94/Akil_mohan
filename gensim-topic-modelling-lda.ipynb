{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling using Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- Clean the reviews\n",
    "- Get the tokens and their ids\n",
    "- Identify bag of words for each document\n",
    "- Use LDA model to get the topics\n",
    "- Assign topic to each document based on probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import combinations\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>06 2, 2013</td>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1.370131e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>11 25, 2010</td>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1.290643e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>09 9, 2010</td>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1.283990e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>11 24, 2010</td>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>1.290557e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>09 29, 2011</td>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>1.317254e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin   helpful  overall  \\\n",
       "0           0  0528881469    [0, 0]      5.0   \n",
       "1           1  0528881469  [12, 15]      1.0   \n",
       "2           2  0528881469  [43, 45]      3.0   \n",
       "3           3  0528881469   [9, 10]      2.0   \n",
       "4           4  0528881469    [0, 0]      1.0   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  We got this GPS for my husband who is an (OTR)...   06 2, 2013   \n",
       "1  I'm a professional OTR truck driver, and I bou...  11 25, 2010   \n",
       "2  Well, what can I say.  I've had this unit in m...   09 9, 2010   \n",
       "3  Not going to write a long review, even thought...  11 24, 2010   \n",
       "4  I've had mine for a year and here's what we go...  09 29, 2011   \n",
       "\n",
       "       reviewerID              reviewerName  \\\n",
       "0   AO94DHGC771SJ                   amazdnu   \n",
       "1   AMO214LNFCEI4           Amazon Customer   \n",
       "2  A3N7T0DY83Y4IG             C. A. Freeman   \n",
       "3  A1H8PY3QHMQQA0  Dave M. Shaw \"mack dave\"   \n",
       "4  A24EV6RXELQZ63               Wayne Smith   \n",
       "\n",
       "                                  summary  unixReviewTime  \n",
       "0                         Gotta have GPS!    1.370131e+09  \n",
       "1                       Very Disappointed    1.290643e+09  \n",
       "2                          1st impression    1.283990e+09  \n",
       "3                 Great grafics, POOR GPS    1.290557e+09  \n",
       "4  Major issues, only excuses for support    1.317254e+09  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('e:/datasets/amazon_reviews/amazon_reviews_11.csv')\n",
    "reviews = reviews[~pd.isnull(reviews['reviewText'])]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Common stop words can be taken directly from nltk corpus. [Refer](http://www.nltk.org/data.html) this documentation for further help in getting data from `nltk`\n",
    "- Custom stop words can be either manually inserted in the below list or can also be directly read from a file\n",
    "- Combine common and custom stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'me', 'my', 'myself', 'we'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_stop_words = nltk.corpus.stopwords.words('english')\n",
    "custom_stop_words = []\n",
    "all_stop_words = np.hstack([common_stop_words, custom_stop_words])\n",
    "all_stop_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean words\n",
    "The below function is used to clean the reviews and to get the word tokens one by one\n",
    "- Convert all text to lower case using `.lower()`\n",
    "- Split the text by space to get individual words: `.split()`\n",
    "- Remove stop words using `setdiff1d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_review(review_text):\n",
    "    words_clean = (re.sub('[^a-z ]', '', review_text.lower()).split())\n",
    "    words_imp = np.setdiff1d(words_clean, all_stop_words)\n",
    "    return words_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a empty list in which we will append nested lists. One list per review.\n",
    "- The below for loop will iterate through each review text and calls the above function for cleaning the text and to get the individual tokens for each document.\n",
    "- One list for each document will be appended to `texts` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for review_text in reviews['reviewText'].dropna().values:\n",
    "    words_token = clean_review(review_text)\n",
    "    texts.append(list(words_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens to IDs\n",
    "- corpora.Dictionary(texts) will identify unique tokens in our corpus\n",
    "- For each token i.e. for each unique word an id will be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(9454 unique tokens: ['addresses', 'around', 'arrived', 'back', 'bad']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dicitionary.token2id` will give a dictionary with unique words. Keys will be tokens, values will be the unique id for each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9454"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id['addresses'],dictionary.token2id['around'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "Bag of words is nothing but frequency of each word in a document. Here will be using `.doc2bow` to get frequency of individual words for each document. Try uncommenting and print the first document in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "# print (corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF - Transformation\n",
    "[Refer](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) this wikipedia article for understanding TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling using LDA\n",
    "Here we are explicity asking for 3 topics. To the model we have to pass our cleaned corpus and dictionary which has the unique tokens with their ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"nook\" + 0.005*\"one\" + 0.005*\"good\" + 0.004*\"like\" + 0.004*\"use\" + 0.004*\"easy\" + 0.004*\"bought\" + 0.004*\"would\" + 0.004*\"get\" + 0.004*\"books\"'),\n",
       " (1,\n",
       "  '0.005*\"use\" + 0.005*\"works\" + 0.004*\"nook\" + 0.004*\"great\" + 0.004*\"one\" + 0.004*\"would\" + 0.004*\"screen\" + 0.004*\"bought\" + 0.004*\"good\" + 0.004*\"price\"'),\n",
       " (2,\n",
       "  '0.005*\"great\" + 0.005*\"one\" + 0.004*\"well\" + 0.004*\"get\" + 0.004*\"tv\" + 0.004*\"much\" + 0.004*\"nook\" + 0.004*\"would\" + 0.004*\"screen\" + 0.003*\"use\"')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus, id2word=dictionary, num_topics=3)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics distribution for each document\n",
    "using `get_document_topics` function to get the probability of each topic in a document. In the following example the probability of first topic is 0.84 and probability of second topic is 0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.84772807660700011), (1, 0.1459467461881922)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(dictionary.doc2bow(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.51998272789982625), (1, 0.46531199807315365), (2, 0.014705274027020153)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(dictionary.doc2bow(texts[50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign topic to each document based on probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['topics'] = [lda.get_document_topics(dictionary.doc2bow(text))[0][0] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic distribution in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    854\n",
       "1    101\n",
       "2     42\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['topics'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
